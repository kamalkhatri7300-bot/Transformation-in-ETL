{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1 : Define Data Transformation in ETL and explain why it is important.\n",
        "\n",
        "- Answer 1\n",
        "\n",
        "Data Transformation is the process of converting data from its raw, source format into a format that is compatible with the target system.\n",
        "\n",
        "Importance:\n",
        "\n",
        "Compatibility: Ensures data from different sources can be integrated.\n",
        "\n",
        "Data Quality: Cleanses errors and inconsistencies.\n",
        "\n",
        "Usability: Aggregates or filters data so it is ready for business analysis and reporting.\n",
        "\n",
        "Question 2 : List any four common activities involved in Data Cleaning.\n",
        "\n",
        "- Answer 2\n",
        "\n",
        "Handling Missing Values: Filling in gaps or removing records with null values.\n",
        "\n",
        "Removing Duplicates: Identifying and deleting redundant entries.\n",
        "\n",
        "Outlier Detection: Identifying and managing data points that fall far outside the expected range.\n",
        "\n",
        "Data Validation: Ensuring data follows specific rules\n",
        "\n",
        "\n",
        "Question 3 : What is the difference between Normalization and Standardization?\n",
        "\n",
        "- Answer 3\n",
        "\n",
        "\n",
        "Question 4 : A dataset has missing values in the “Age” column. Suggest two techniques to handle this and explain when they should be used.\n",
        "\n",
        "- Answer 4\n",
        "\n",
        "Mean/Median Imputation: Replace missing values with the average (Mean) or middle value of the column.\n",
        "\n",
        "Use when: The amount of missing data is small and the distribution is relatively uniform.\n",
        "\n",
        "Deletion : Remove the entire row where the Age is missing.\n",
        "\n",
        "Use when: The dataset is very large and the missing values are \"Missing Completely at Random,\" so their removal doesn't bias the results.\n",
        "\n",
        "\n",
        "Question 5 : Convert the following inconsistent “Gender” entries into a standardized format (“Male”, “Female”):\n",
        "\n",
        "- Answer 5\n",
        "\n",
        "\"M\", \"male\", \"MALE\" $\\rightarrow$ Male\n",
        "\n",
        "\"F\", \"Female\", \"f\" $\\rightarrow$ Female\n",
        "\n",
        "Question 6 : What is One-Hot Encoding? Give an example with the categories: “Red, Blue, Green”.\n",
        "\n",
        "- Answer 6\n",
        "\n",
        "One-Hot Encoding is a process used to convert categorical variables into a binary format (1s and 0s) so that machine learning algorithms can process them without assuming an inherent order.\n",
        "\n",
        "Example:\n",
        "Red: [1, 0, 0]\n",
        "Blue: [0, 1, 0]\n",
        "Green: [0, 0, 1]\n",
        "\n",
        "\n",
        "Question 7 : Explain the difference between Data Integration and Data Mapping in ETL.\n",
        "\n",
        "- Answer 7\n",
        "\n",
        "Data Integration: The high-level process of combining data from different sources to provide a unified view.\n",
        "\n",
        "Data Mapping: The specific technical step of \"linking\" a field in the source to a field in the target.\n",
        "\n",
        "\n",
        "Question 8 : Explain why Z-score Standardization is preferred over Min-Max Scaling when outliers exist\n",
        "\n",
        "- Answer 8\n",
        "\n",
        "Min-Max Scaling is highly sensitive to outliers because it uses the absolute minimum and maximum values. If one value is 1,000,000 while the rest are under 100, Min-Max will \"squash\" all the normal data into a tiny range.\n",
        "\n",
        "Z-score Standardization is preferred because it uses the mean and standard deviation, which are less affected by extreme values, allowing the relative distribution of the \"normal\" data to remain distinct."
      ],
      "metadata": {
        "id": "5o85-SpQPqXC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bsc9F6TOPohw"
      },
      "outputs": [],
      "source": []
    }
  ]
}